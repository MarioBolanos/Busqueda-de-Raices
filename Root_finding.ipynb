{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "name": "Copia de Root finding.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarioBolanos/Busqueda-de-Raices/blob/master/Root_finding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XeRXbaLrkzV",
        "colab_type": "text"
      },
      "source": [
        "# Root finding Methods\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-KG3dULrkzX",
        "colab_type": "text"
      },
      "source": [
        "### The Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzVlQm6rrkzY",
        "colab_type": "text"
      },
      "source": [
        "How can we find the root $x_0$ of a function $f(x)$, i.e.\n",
        "$$f(x_0) = 0,$$\n",
        "if we cannot determine it with pencil and paper.\n",
        "\n",
        "Note that there could be more than one root and we would like to have some control over which root is computed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-3O-CWZrkzY",
        "colab_type": "text"
      },
      "source": [
        "### Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beVCeEOhrkzZ",
        "colab_type": "text"
      },
      "source": [
        "We would like to know where the function $g(x) = x$ intersects the function $h(x) = e^{-x}$. In other words, we need to solve\n",
        "$$x = e^{-x}.$$\n",
        "This is equivalent to finding the root of $f(x) = e^{-x} − x = 0:$\n",
        "$$f(x_0)=e^{−x_0} −x_0 =0.$$\n",
        "Let us plot the two functions g and h to gauge whether there might be a root and, if so, where approximately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ct8fVk3rkzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j07qRR1erkzg",
        "colab_type": "text"
      },
      "source": [
        "We see that the intersection appears near $x = 0.6$. Since both $g$ and $h$ are monotonic functions, they only intersect once. Correspondingly, f should have one unique root near x = 0.6, as is shown in the graph below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e0dafj6rkzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpKqKtI7tQXo",
        "colab_type": "text"
      },
      "source": [
        "## Bisection Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hV1paJFrkzj",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "How can we find this root?\n",
        "\n",
        "Well, we know that the root definitely lies between $x = 0$ and $x = 1$ since $f(x)$ is monotonically decreasing and\n",
        "$$f(0) = 1,$$\n",
        "and hence positive, and\n",
        "$$f(1) = \\frac{1}{e} − 1 = −0.6321,$$\n",
        "and hence negative. The root must lie somewhere in between.\n",
        "\n",
        "The strategy is now to \"zero in\" on the root by checking values of the function closer and closer to the (unknown) root."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3la0Zzkzrkzj",
        "colab_type": "text"
      },
      "source": [
        "To do so, let’s divide the interval $[0, 1]$ whose endpoints we have just studied, into halves by choosing the midpoint $x = 0.5$. The value of $f$ at the midpoint is\n",
        "$$f (0.5) = 0.1065,$$\n",
        "and therefore positive. Since $f(1) < 0$, we now know that the root lies somewhere between $x = 0.5$ and $x = 1$. Similar to the last step, we now choose the midpoint of the interval $[0.5, 1]$ to check the value of the function:\n",
        "$$f(0.75) = −0.2776.$$\n",
        "The root must therefore fall within the interval $[0.5, 0.75]$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD7eU60yrkzk",
        "colab_type": "text"
      },
      "source": [
        "We can continue to repeat these steps, resulting in ever smaller intervals in which the root must lie. It can happen, although it is unlikely, that one of the midpoints that we finally choose coincides with the root. This is a highly unusual case though.\n",
        "We truncate this method when we are satisfied with the precision with which we have determined the root. It is simply given by the width of the last interval. Note that we cannot exceed the machine precision of our computer, setting a limit to our division of intervals.\n",
        "The above method is called the __bisection algorithm__."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nShmtfiGrkzk",
        "colab_type": "text"
      },
      "source": [
        "We can now write the bisection algorithm systematically.\n",
        "Given a (continuous) function $f(x)$, a root, if it exists, can be approximated in the following way:\n",
        "Find two values $x_p$ and $x_m$ with $f(x_p) > 0$ and $f(x_m) < 0$. Then, follow these steps:\n",
        "1. Choose the midpoint $x_\\mathrm{next} = \\frac{x_p+x_m}{2}.$\n",
        "2. If $f(x_\\mathrm{next})$ has the same sign as $f(x_p)$, then we set $x_p = x_\\mathrm{next}$.\n",
        "3. Otherwise, we set $x_m = x_\\mathrm{next}$.\n",
        "4. Repeat the previous three steps until the desired accuracy is reached.\n",
        "\n",
        "It is as simple as that. Let's determine the root of $f(x)$ up to a given accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aso1pravrkzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhiOn7IEtbBl",
        "colab_type": "text"
      },
      "source": [
        "## Newton-Raphson Algorithm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iujlzPKrrkzo",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "The idea is to start with a guess $x_1$ and the corresponding point on the graph $(x_1 , f(x_1))$. Let’s pick $x_1 = −0.5$. Then we \"follow\" the line tangent to the graph at that point until we hit the x-axis.\n",
        "\n",
        "The intersection of tangent line and $x$-axis gives us a new estimate, $x_2$, of the root. As we can see, we are indeed closer to the real root now.\n",
        "\n",
        "We can repeat this procedure, i.e. following a tangent line at $x_2$ until we hit the $x$-axis again. This yields our next guess $x_3$, and so on.\n",
        "\n",
        "From the previous plot, we can see that the difference $\\Delta x$ (where $\\Delta x = x_\\mathrm{next} − x_\\mathrm{cur})$ between the current guess, $x_\\mathrm{cur}$, and the next guess, $x_\\mathrm{next}$, is related to the slope of the tangent line, $f′(x_\\mathrm{cur})$, via (note the minus sign)\n",
        "$$f′(x_\\mathrm{cur}) = −\\frac{f(x_\\mathrm{cur})}{\\Delta x}.$$\n",
        "\n",
        "This yields\n",
        "$$x_\\mathrm{next} =x_\\mathrm{cur} +\\Delta x = x_\\mathrm{cur} − \\frac{f(x_\\mathrm{cur})}{f'(x_\\mathrm{cur})}.$$\n",
        "This procedure can be formulated as the following __Newton-Raphson algorithm__ (also called Newton’s method):\n",
        "1. Guess a value $x_\\mathrm{cur}$ of the root of the function $f(x)$. Sometimes, plotting helps to guess a value (see above).\n",
        "2. If there is more than one root, try to choose a value close to the root one is interested in.\n",
        "3. Set $x_\\mathrm{next} = x_\\mathrm{cur} − \\frac{f(x_\\mathrm{cur})}{f'(x_\\mathrm{cur})}$ as the next estimate of the root.\n",
        "4. Set $x_\\mathrm{cur} = x_\\mathrm{next}$.\n",
        "5. Repeat steps 3 and 4 until desired accuracy is achieved.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCoxUrrrrrN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef8u3FCOrIKH",
        "colab_type": "text"
      },
      "source": [
        "Accuracy can refer to two phenomena:\n",
        "1. When the algorithm converges, $\\Delta x$ ultimately decreases with each iteration. The question is: at what value of $\\Delta x$ should we stop our iterative procedure?\n",
        "2. How close is $f(x_\\mathrm{cur})$ to zero?\n",
        "\n",
        "Note: In each case, we cannot be sure how close we really are to the actual root $x_0$. This has a lot to do with the behavior of the function $f$ near $x_0$.\n",
        "- In case 1, $\\Delta x$ could in principle increase again during the next iteration.\n",
        "- In case 2, the magnitude of $f(x_\\mathrm{cur})$ could in principle increase again in the next iteration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpRFeCjErIKH",
        "colab_type": "text"
      },
      "source": [
        "If the root lies in a region where $f(x)$ is nearly linear, the algorithm will converge quickly, much faster than the bisection algorithm.\n",
        "\n",
        "However, there is generally no guarantee that the algorithm converges. Two phenomena frequently occur when the Newton-Raphson algorithm is applied. Let us discuss them one by one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wknnXFkmrIKI",
        "colab_type": "text"
      },
      "source": [
        "__Problem No. 1:__\n",
        "The derivative $f′(x_\\mathrm{cur})$ can sometimes become very small, making $\\Delta x = − \\frac{f(x_\\mathrm{cur})}{f′(x_\\mathrm{cur})}$ very large. This is the case near local minima and maxima, or potentially at a (horizontal) inflection\n",
        "point.\n",
        "\n",
        "The next guess $x_\\mathrm{next}$ is then far away from the actual root. The computer code may stop due to numbers too large in nature, or one enters the region of another root. In other words, one does not return to anywhere near the root of interest.\n",
        "In this case, the initial guess needs to be changed. Or we can limit the step size $\\Delta x$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukNi3kS0rIKJ",
        "colab_type": "text"
      },
      "source": [
        "__Problem No. 2:__\n",
        "The algorithm does neither converge or diverge. Rather, it remains within the vicinity of the root, oscillating in an infinite loop about the actual root without approaching it.\n",
        "\n",
        "Again, the initial guess needs to be changed. Or we need to reduce the step size further (relaxation): we can replace $\\Delta x$ by $\\gamma \\Delta x$, with $0 < \\gamma < 1$.\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2NGVpMFrIKK",
        "colab_type": "text"
      },
      "source": [
        "Sometimes, it can be useful to use the slower but reliable bisection method first so as to get close enough to the actual root to provide a good initial guess for the faster Newton-Raphson method. The latter takes over at some point, providing better convergence.\n",
        "\n",
        "Another useful trick is to approximate the derivative $f′(x_\\mathrm{cur})$ by \n",
        "$$f′(x_\\mathrm{cur}) \\approx \\frac{f(x_\\mathrm{cur} + \\delta x)−f(x_\\mathrm{cur})}{\\delta x}$$\n",
        "for some small value $\\delta x$. This comes in handy when the derivative cannot be computed easily in analytical form and a numerical estimate is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPo1-w5NrIKL",
        "colab_type": "text"
      },
      "source": [
        "__Example 2:__\n",
        "\n",
        "We want to solve the equation\n",
        "$$ 2 - x^4 = \\tanh(x)$$\n",
        "for $x > 0$. Hence, we need to solve\n",
        "$$f(x) = 2 - x^4 - \\tanh(x).$$\n",
        "Our algorithm reads\n",
        "$$\n",
        "\\begin{align}\n",
        "x_\\mathrm{next} = x_\\mathrm{cur} - \\frac{f(x_\\mathrm{cur})}{f'(x_\\mathrm{cur})} = \\frac{2-x_\\mathrm{cur}^4-\\tanh(x_\\mathrm{cur})}{-4 x_\\mathrm{cur}^3-\\frac{1}{\\cosh(x_\\mathrm{cur})^2}}.\n",
        "\\end{align}\n",
        "$$\n",
        "Plotting $f(x)$ helps us in making an initial guess."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcNT-sS3rIKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4_8ytLjrIKS",
        "colab_type": "text"
      },
      "source": [
        "We choose $x_\\mathrm{cur} = x_1 = 1.0$.\n",
        "\n",
        "We now iterate and find the following successive estimates for the root for the first 5 iterations (up to 12 significant digits):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtbZmzixrIKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QByTxcftrIKc",
        "colab_type": "text"
      },
      "source": [
        "We see that 5 iterations are sufficient in this case!\n",
        "The bisection algorithm would require many more iterations for the same accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5FwBFOwrIKd",
        "colab_type": "text"
      },
      "source": [
        "The value of $f(x)$ for our final root estimate is\n",
        "$$f(1.05053505396) =  -2.22044604925 \\times 10^{-16}.$$\n",
        "A very good estimate!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75O9uOSjrIKd",
        "colab_type": "text"
      },
      "source": [
        "__Note:__\n",
        "Newton’s method can be extended to higher dimensions, i.e. having $k$ variables and $k$ functions of which we need to find the roots simultaneously. This is particularly relevant for numerical solutions of differential equations. However, these intricacies of Newton’s method will not be covered in this module."
      ]
    }
  ]
}